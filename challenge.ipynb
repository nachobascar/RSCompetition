{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from typing import Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_SHRINK_TERM = 5\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764602</th>\n",
       "      <td>35735</td>\n",
       "      <td>37802</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764603</th>\n",
       "      <td>35735</td>\n",
       "      <td>37803</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764604</th>\n",
       "      <td>35735</td>\n",
       "      <td>37805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764605</th>\n",
       "      <td>35735</td>\n",
       "      <td>38000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764606</th>\n",
       "      <td>35735</td>\n",
       "      <td>38034</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764607 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  data\n",
       "0              0        0   1.0\n",
       "1              0        2   1.0\n",
       "2              0      120   1.0\n",
       "3              0      128   1.0\n",
       "4              0      211   1.0\n",
       "...          ...      ...   ...\n",
       "1764602    35735    37802   1.0\n",
       "1764603    35735    37803   1.0\n",
       "1764604    35735    37805   1.0\n",
       "1764605    35735    38000   1.0\n",
       "1764606    35735    38034   1.0\n",
       "\n",
       "[1764607 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feature_df = pd.read_csv('data_ICM_metadata.csv')\n",
    "target_users_df = pd.read_csv('data_target_users_test.csv')\n",
    "train_df = pd.read_csv('data_train.csv')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736 0 35735\n",
      "38121 0 38120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>data</th>\n",
       "      <th>mapped_user_id</th>\n",
       "      <th>mapped_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764602</th>\n",
       "      <td>34967</td>\n",
       "      <td>37744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34967</td>\n",
       "      <td>38120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764603</th>\n",
       "      <td>35040</td>\n",
       "      <td>37744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35040</td>\n",
       "      <td>38120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764604</th>\n",
       "      <td>35308</td>\n",
       "      <td>37744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35308</td>\n",
       "      <td>38120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764605</th>\n",
       "      <td>35431</td>\n",
       "      <td>37744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35431</td>\n",
       "      <td>38120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764606</th>\n",
       "      <td>35733</td>\n",
       "      <td>37744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35733</td>\n",
       "      <td>38120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  data  mapped_user_id  mapped_item_id\n",
       "0              0        0   1.0               0               0\n",
       "1              5        0   1.0               5               0\n",
       "2              6        0   1.0               6               0\n",
       "3              7        0   1.0               7               0\n",
       "4              9        0   1.0               9               0\n",
       "...          ...      ...   ...             ...             ...\n",
       "1764602    34967    37744   1.0           34967           38120\n",
       "1764603    35040    37744   1.0           35040           38120\n",
       "1764604    35308    37744   1.0           35308           38120\n",
       "1764605    35431    37744   1.0           35431           38120\n",
       "1764606    35733    37744   1.0           35733           38120\n",
       "\n",
       "[1764607 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(users: pd.DataFrame):\n",
    "    unique_users = users.user_id.unique()\n",
    "    unique_items = users.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = (\n",
    "        unique_users.size,\n",
    "        unique_users.min(),\n",
    "        unique_users.max(),\n",
    "    )\n",
    "    num_items, min_item_id, max_item_id = (\n",
    "        unique_items.size,\n",
    "        unique_items.min(),\n",
    "        unique_items.max(),\n",
    "    )\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame(\n",
    "        {\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users}\n",
    "    )\n",
    "    mapping_item_id = pd.DataFrame(\n",
    "        {\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items}\n",
    "    )\n",
    "\n",
    "    users = pd.merge(left=users, right=mapping_user_id, how=\"inner\", on=\"user_id\")\n",
    "\n",
    "    users = pd.merge(left=users, right=mapping_item_id, how=\"inner\", on=\"item_id\")\n",
    "\n",
    "    return users\n",
    "\n",
    "users = preprocess_data(train_df)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38121x94331 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2940040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert into sparse matrix items x features\n",
    "item_idx, item_map = pd.factorize(item_feature_df[\"item_id\"])\n",
    "feature_idx, feature_map = pd.factorize(item_feature_df[\"feature_id\"])\n",
    "\n",
    "items_sparse_matrix = sp.csr_matrix((item_feature_df['data'], (item_idx, feature_idx)), \n",
    "                           shape=(len(item_map), len(feature_map)))\n",
    "items_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35736x38121 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1270516 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def dataset_splits(\n",
    "    users,\n",
    "    num_users,\n",
    "    num_items,\n",
    "    validation_percentage: float,\n",
    "    testing_percentage: float,\n",
    "):\n",
    "    seed = 1234\n",
    "\n",
    "    (\n",
    "        user_ids_training,\n",
    "        user_ids_test,\n",
    "        item_ids_training,\n",
    "        item_ids_test,\n",
    "        data_training,\n",
    "        data_test,\n",
    "    ) = train_test_split(\n",
    "        users.mapped_user_id,\n",
    "        users.mapped_item_id,\n",
    "        users.data,\n",
    "        test_size=testing_percentage,\n",
    "        shuffle=True,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    (\n",
    "        user_ids_training,\n",
    "        user_ids_validation,\n",
    "        item_ids_training,\n",
    "        item_ids_validation,\n",
    "        data_training,\n",
    "        data_validation,\n",
    "    ) = train_test_split(\n",
    "        user_ids_training,\n",
    "        item_ids_training,\n",
    "        data_training,\n",
    "        test_size=validation_percentage,\n",
    "    )\n",
    "\n",
    "    urm_train = sp.csr_matrix(\n",
    "        (data_training, (user_ids_training, item_ids_training)),\n",
    "        shape=(num_users, num_items),\n",
    "    )\n",
    "\n",
    "    urm_validation = sp.csr_matrix(\n",
    "        (data_validation, (user_ids_validation, item_ids_validation)),\n",
    "        shape=(num_users, num_items),\n",
    "    )\n",
    "\n",
    "    urm_test = sp.csr_matrix(\n",
    "        (data_test, (user_ids_test, item_ids_test)), shape=(num_users, num_items)\n",
    "    )\n",
    "\n",
    "    return urm_train, urm_validation, urm_test\n",
    "\n",
    "urm_train, urm_validation, urm_test = dataset_splits(\n",
    "    users,\n",
    "    num_users=35736,\n",
    "    num_items=38121,\n",
    "    validation_percentage=0.10,\n",
    "    testing_percentage=0.20,\n",
    ")\n",
    "urm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(urm: sp.csc_matrix, shrink: int):\n",
    "    item_weights = np.sqrt(np.sum(urm.power(2), axis=0)).A.flatten()\n",
    "\n",
    "    num_items = urm.shape[1]\n",
    "    urm_t = urm.T\n",
    "    weights = np.empty(shape=(num_items, num_items))\n",
    "    for item_id in range(num_items):\n",
    "        numerator = urm_t.dot(urm[:, item_id]).A.flatten()\n",
    "        denominator = item_weights[item_id] * item_weights + shrink + 1e-6\n",
    "\n",
    "        weights[item_id] = numerator / denominator\n",
    "\n",
    "    np.fill_diagonal(weights, 0.0)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def matrix_similarity(urm: sp.csc_matrix, shrink: int):\n",
    "    item_weights = np.sqrt(np.sum(urm.power(2), axis=0)).A\n",
    "\n",
    "    numerator = urm.T.dot(urm)\n",
    "    denominator = item_weights.T.dot(item_weights) + shrink + 1e-6\n",
    "    weights = numerator / denominator\n",
    "    np.fill_diagonal(weights, 0.0)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CFItemKNN at 0x25717c5d2b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CFItemKNN(object):\n",
    "    def __init__(self, shrink: int):\n",
    "        self.shrink = shrink\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, urm_train: sp.csc_matrix, similarity_function):\n",
    "        if not sp.isspmatrix_csc(urm_train):\n",
    "            raise TypeError(f\"We expected a CSC matrix, we got {type(urm_train)}\")\n",
    "\n",
    "        self.weights = similarity_function(urm_train, self.shrink)\n",
    "\n",
    "    def recommend(\n",
    "        self,\n",
    "        user_id: int,\n",
    "        urm_train: sp.csr_matrix,\n",
    "        at: Optional[int] = None,\n",
    "        remove_seen: bool = True,\n",
    "    ):\n",
    "        user_profile = urm_train[user_id]\n",
    "\n",
    "        ranking = user_profile.dot(self.weights).A.flatten()\n",
    "\n",
    "        if remove_seen:\n",
    "            user_profile_start = urm_train.indptr[user_id]\n",
    "            user_profile_end = urm_train.indptr[user_id + 1]\n",
    "\n",
    "            seen_items = urm_train.indices[user_profile_start:user_profile_end]\n",
    "\n",
    "            ranking[seen_items] = -np.inf\n",
    "\n",
    "        ranking = np.flip(np.argsort(ranking))\n",
    "        return ranking[:at]\n",
    "\n",
    "itemknn_recommender = CFItemKNN(shrink=50)\n",
    "itemknn_recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 28.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "itemknn_recommender.fit(urm_train.tocsc()[:1000,:1000], matrix_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m----> 3\u001b[0m         \u001b[43mitemknn_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murm_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murm_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_seen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     )\n",
      "Cell \u001b[1;32mIn [41], line 21\u001b[0m, in \u001b[0;36mCFItemKNN.recommend\u001b[1;34m(self, user_id, urm_train, at, remove_seen)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     14\u001b[0m     user_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     remove_seen: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m ):\n\u001b[0;32m     19\u001b[0m     user_profile \u001b[38;5;241m=\u001b[39m urm_train[user_id]\n\u001b[1;32m---> 21\u001b[0m     ranking \u001b[38;5;241m=\u001b[39m \u001b[43muser_profile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mA\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_seen:\n\u001b[0;32m     24\u001b[0m         user_profile_start \u001b[38;5;241m=\u001b[39m urm_train\u001b[38;5;241m.\u001b[39mindptr[user_id]\n",
      "File \u001b[1;32mc:\\Users\\nacho\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\sparse\\_base.py:416\u001b[0m, in \u001b[0;36mspmatrix.dot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m*\u001b[39m other\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nacho\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\sparse\\_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nacho\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\sparse\\_base.py:577\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# dense 2D array or matrix (\"multivector\")\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    579\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_multivector(np\u001b[38;5;241m.\u001b[39masarray(other))\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, np\u001b[38;5;241m.\u001b[39mmatrix):\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "for user_id in range(10):\n",
    "    print(\n",
    "        itemknn_recommender.recommend(\n",
    "            user_id=user_id, urm_train=urm_train, at=10, remove_seen=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
